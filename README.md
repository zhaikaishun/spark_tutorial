spark RDD的算子挺多，有时候如何灵活的使用，该如何用一下子想不起来，这一段时间将spark的算子如何使用的例子给记录了下来，下面是spark RDD 的一些常用算子的使用  
这些算子包括有java的，也有scala的语言，由于精力有限，暂时没有python的，以后有空再加上吧  
[spark RDD算子（一） parallelize，makeRDD，textFile](http://blog.csdn.net/t1dmzks/article/details/70189509)  
  
  
[spark RDD算子（二） filter,map ,flatMap](http://blog.csdn.net/t1dmzks/article/details/70198393)    
  
  
[spark RDD算子（三） distinct，union，intersection，subtract，cartesian](http://blog.csdn.net/t1dmzks/article/details/70198430)    
  
  
[spark RDD算子（四）之创建键值对RDD mapToPair flatMapToPair](http://blog.csdn.net/t1dmzks/article/details/70234272)  
  
  
[spark RDD算子（五）之键值对聚合操作 combineByKey](http://blog.csdn.net/t1dmzks/article/details/70249743)  
  
  
[spark RDD算子（六）之键值对聚合操作reduceByKey，foldByKey，排序操作sortByKey](http://blog.csdn.net/t1dmzks/article/details/70342732)    
  
  
[spark RDD算子（七）之键值对分组操作 groupByKey，cogroup](http://blog.csdn.net/t1dmzks/article/details/70549752)  
  
  
[spark RDD算子（八）之键值对关联操作 subtractByKey, join, rightOuterJoin, leftOuterJoin](http://blog.csdn.net/t1dmzks/article/details/70557249)    
  
  
[spark RDD算子（九）之基本的Action操作 first, take, collect, count, countByValue, reduce, aggregate, fold,top](http://blog.csdn.net/t1dmzks/article/details/70667011) 
  
  
[spark RDD算子（十）之PairRDD的Action操作countByKey, collectAsMap](http://blog.csdn.net/t1dmzks/article/details/70833185)    
  
  
[spark RDD算子（十一）之RDD Action 保存操作saveAsTextFile,saveAsSequenceFile,saveAsObjectFile,saveAsHadoopFile 等](http://blog.csdn.net/t1dmzks/article/details/71037850)   
  
  

[spark RDD算子（十二）之RDD 分区操作上mapPartitions, mapPartitionsWithIndex](http://blog.csdn.net/t1dmzks/article/details/71336119)    
  
  
[spark RDD算子（十三）之RDD 分区 HashPartitioner，RangePartitioner，自定义分区](http://blog.csdn.net/t1dmzks/article/details/71374418)
